{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 2\n",
    "\n",
    "## [Daoyang E] - [de2418]\n",
    "\n",
    "### Due: Fri Mar 11th @ 11:59pm ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and hyperparameter tuning in both a regression and classification setting.\n",
    "\n",
    "We will be working with a small set of home sales data as we might see on a real-estate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Follow the comments below and fill in the blanks (\\_\\_\\_\\_) to complete.\n",
    "- Please **'Restart and Run All'** prior to submission.\n",
    "- **Save pdf in Landscape** and **check that all of your code is shown** in the submission.\n",
    "- When submitting in Gradescope, be sure to **select which page corresponds to which question.**\n",
    "\n",
    "Out of 50 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts) Set up our environment with common libraries and plot settings.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy as np, pandas as pd, matplotlib.pyplot as plt and seaborn as sns\n",
    "# Note: use as many lines of code as necessary\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns;\n",
    "\n",
    "# Set the seaborn style to 'darkgrid'\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Execute the matplotlib magic function to ensure plots are displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1 we will try to predict a real value home sale price using several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='AdjSalePrice_x100000', ylabel='Count'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. (4pts) Load and prepare our data.\n",
    "\n",
    "# Read in the csv file ../data/house_sales_subset.csv using pandas read_csv() with default parameter settings\n",
    "df = pd.read_csv(\"../data/house_sales_subset.csv\")\n",
    "\n",
    "# Create a dataframe X which contains these 3 columns from df:\n",
    "#  'SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms'\n",
    "X = pd.DataFrame(data = df, columns = ['SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms'])\n",
    "\n",
    "# Create a series y_r which contains only the column AdjSalePrice_x100000\n",
    "#    Note: the '_r' is for our regression target\n",
    "y_r = df['AdjSalePrice_x100000']\n",
    "\n",
    "# Check that X and y_r is the correct shape\n",
    "assert X.shape == (1000,3)\n",
    "assert y_r.shape == (1000,)\n",
    "\n",
    "# To confirm that all features of X are similar in scale display the .describe() of X\n",
    "X.describe()\n",
    "\n",
    "# To get a sense of the distribution of the target, plot a histogram of y_r using sns.histplot()\n",
    "sns.histplot(y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of data in test set: 0.20\n"
     ]
    }
   ],
   "source": [
    "# 3. (3pts) Create a held-aside set\n",
    "\n",
    "# Import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y_r into 80% train and 20% test using train_test_split\n",
    "#   Use random_state=123 for grading consistency.\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y_r, test_size=0.2, random_state = 123)\n",
    "\n",
    "# Print out the the length of y_test_r divided by the length y_r  to confirm our test set size.\n",
    "print(f'proportion of data in test set: {len(y_test_r)/len(y_r):0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Baseline Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy training set R^2: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 4. (3pts) Create a DummyRegressor and fit on the training set.\n",
    "\n",
    "# Import the DummyRegressor model from sklearn \n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Instantiate a DummyRegessor model with strategy=\"mean\" \n",
    "dummy_r = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# Train the DummyRegressor on the regression training set\n",
    "dummy_r.fit(X_train_r, y_train_r)\n",
    "\n",
    "# Calculate and print the training set R^2 score of the DummyRegressor\n",
    "dummy_r_training_r2 = dummy_r.score(X_train_r, y_train_r)\n",
    "\n",
    "print(f'dummy training set R^2: {dummy_r_training_r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Linear Regression and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr training set R^2: 0.53\n"
     ]
    }
   ],
   "source": [
    "# 5. (4pts) Train a Linear Regression model and calculate training set R^2.\n",
    "\n",
    "# Import the LinearRegression model from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate a LinearRegression model with default arguments and fit on the training set\n",
    "lr = LinearRegression().fit(X_train_r, y_train_r)\n",
    "\n",
    "# Calculate and print the training set R^2 of the LinearRegression model\n",
    "lr_training_r2 = lr.score(X_train_r, y_train_r)\n",
    "\n",
    "print(f'lr training set R^2: {lr_training_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48, 0.58, 0.5 , 0.44, 0.58])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. (2pts) Use 5-fold Cross Validation to get a sense of variation \n",
    "#    of Liner Regression R^2 performance on the training set.\n",
    "\n",
    "# Import cross_val_score from sklearn.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Generate 5-fold cross-validation R^2 scores \n",
    "#    for a LinearRegression model with default arguments \n",
    "#    on the training set\n",
    "lr_cv_scores = cross_val_score(LinearRegression(), X_train_r, y_train_r, cv = 5)\n",
    "\n",
    "# Print out the R^2 scores found by cross_val_score\n",
    "np.round(lr_cv_scores,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr mean cv r2: 0.52 +- 0.11\n"
     ]
    }
   ],
   "source": [
    "# 7. (1pts) Calculate mean cv R^2 score +- 2 std. deviations\n",
    "\n",
    "# Calculate the mean cross validation score using the scores created above\n",
    "lr_cv_mean = lr_cv_scores.mean()\n",
    "\n",
    "# Calculate 2 standard deviations of the cross validation scores\n",
    "lr_cv_2std = lr_cv_scores.std()*2\n",
    "\n",
    "# Print out the mean R^2 +- 2 standard variations for the LinearRegression model\n",
    "print(f'lr mean cv r2: {lr_cv_mean:.2f} +- {lr_cv_2std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy test R2 : -0.01\n",
      "   lr test R2 :  0.47\n"
     ]
    }
   ],
   "source": [
    "# 8. (2pts) Evaluate performance of our trained DummyRegressor and LinearRegression model on the test set.\n",
    "\n",
    "# Calculate R^2 on the test set using the previously trained models\n",
    "dummy_r_test_r2 = dummy_r.score(X_test_r, y_test_r)\n",
    "\n",
    "lr_test_r2 = lr.score(X_test_r, y_test_r)\n",
    "\n",
    "print(f'dummy test R2 : {dummy_r_test_r2: .2f}')\n",
    "print(f'   lr test R2 : {lr_test_r2: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build several models to classify low vs. high adjusted sales price, creating a validation curve and performing grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reuse the same dataset, we'll first create a binary target for \n",
    "#    classification by thresholding at the mean of our AdjSalePrice\n",
    "\n",
    "# The classes are:\n",
    "#    Low AdjSalePrice  = 0\n",
    "#    High AdjSalePrice = 1\n",
    "\n",
    "y_c = (df.AdjSalePrice_x100000 > df.AdjSalePrice_x100000.mean()).astype(int)\n",
    "\n",
    "# Print out the unique labels and note it's 0,1 or binary classification\n",
    "y_c.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Create a Held-Aside Aet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of low values: 0.59\n"
     ]
    }
   ],
   "source": [
    "# 9. (3pts) Create a training and test/held-aside set\n",
    "\n",
    "# Split into 80% train and 20% test using train_test_split \n",
    "#    Use the new y_c target and the same X we used for regression\n",
    "#    Stratify according to y_c so class proportions are the same in train and test\n",
    "#    Use random_state=123 for reproducibility\n",
    "#    Save the result into the variables X_train_c,X_test_c,y_train_c,y_test_c\n",
    "X_train_c,X_test_c,y_train_c,y_test_c = train_test_split(X, y_c, test_size=0.2, stratify = y_c, random_state=123)\n",
    "\n",
    "# Print out the proportion of Low values (label of 0) in y_c\n",
    "print(f'proportion of low values: {sum(y_c == 0)/len(y_c):0.2f}')\n",
    "\n",
    "# Assert that train and test have similar class proportions.\n",
    "# Find the proportion of Low (0) values in both y_train_c and y_test_c and \n",
    "#    assert that the absolute difference of these proportions is less than .01\n",
    "assert abs(sum(y_train_c == 0)/len(y_train_c)-sum(y_test_c == 0)/len(y_test_c)) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy training set accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "# 10. (2pts)  Create a Dummy Classifier and confirm the expected performance on the training set.\n",
    "\n",
    "# Import DummyClassifier from sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Instantiate and a DummyClassifier with strategy=\"most_frequent\" and fit on the the training set\n",
    "dummy_c = DummyClassifier(strategy=\"most_frequent\").fit(X_train_c, y_train_c)\n",
    "\n",
    "# Print the trained DummyClassifier accuracy on the training set.\n",
    "# It should match the proportion of low values we saw above.\n",
    "print(f'dummy training set accuracy: {dummy_c.score(X_train_c, y_train_c):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3  Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logr mean cv accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# 11. (3pts) It's good practice to start with a \"simple\" model.\n",
    "#     Train and calculate 5-fold cv training set accuracy for a Logistic Regression Classifier.\n",
    "\n",
    "# Import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Generate 5-fold cross validation accuracy on the training set\n",
    "#    using LogisticRegression with default hyperparameters\n",
    "#    store as logr_cvscores\n",
    "logr_cv_scores = cross_val_score(LogisticRegression(),X_train_c,y_train_c, cv = 5)\n",
    "\n",
    "# Print out the mean cv accuracy for the LogisticRegression model\n",
    "print(f'logr mean cv accuracy: {logr_cv_scores.mean():0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 GradientBoosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc mean cv accuracy: 0.80 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "# 12. (4pts) Now let's try a more complex model.\n",
    "#     Train and calculate 5-fold cv accuracy \n",
    "#     for a GradientBoosting model using the training set.\n",
    "\n",
    "# Import the GradientBoostingClassifier model from sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Calculate 5-fold cv training set accuracy scores for a GradientBoostingClassifier\n",
    "#   with 50 trees and max_depth=2\n",
    "#   To speed up training also set n_jobs=-1 in the cross_val_score (use one core for each fold)\n",
    "gbc_cv = cross_val_score(GradientBoostingClassifier(n_estimators = 50, max_depth=2), X_train_c, y_train_c, cv = 5, n_jobs=-1)\n",
    " \n",
    "# Calculate mean cv accuracy\n",
    "gbc_cv_mean = gbc_cv.mean()\n",
    "\n",
    "# Calculate 2 standard deviations for the cv scores\n",
    "gbc_cv_2std = gbc_cv.std()*2\n",
    "\n",
    "print(f'gbc mean cv accuracy: {gbc_cv_mean:.2f} +- {gbc_cv_2std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 GradientBoosting and Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>max_depth</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_train_scores</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_scores</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "max_depth            1     2     3     5     10\n",
       "mean_train_scores  0.81  0.84  0.87  0.95  0.99\n",
       "mean_test_scores   0.79  0.81  0.81  0.79  0.76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13. (5pts) Let's investigate how the depth of trees (max_depth) affects performance.\n",
    "#     Generate a validation curve for tree depths in the GradientBoosting model.\n",
    "\n",
    "# Import the validation_curve function from sklearn\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# In the GradientBoostingClassifier model, the depth of trees is set via max_depth\n",
    "# Here we'll try the depths 1,2,3,5,10\n",
    "depths = [1,2,3,5,10]\n",
    "\n",
    "# Generate the train_scores and test_scores for max_depth at different max_depths\n",
    "#   Use the validation_curve function\n",
    "#   Use a GradientBoostingClassiier with 50 trees\n",
    "#   Use our training set X_train_c, y_train_c\n",
    "#   Use the 'max_depth' parameter\n",
    "#   Use the depths list created above as the parameter range\n",
    "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
    "#   Use accuracy as the scoring metric\n",
    "#   Store the results in train_scores,test_scores\n",
    "train_scores,test_scores = validation_curve(GradientBoostingClassifier(n_estimators = 50),\n",
    "                                            X_train_c, y_train_c,\n",
    "                                            param_name='max_depth',\n",
    "                                            param_range= depths,\n",
    "                                            scoring = \"accuracy\",\n",
    "                                            cv=3)\n",
    "\n",
    "# train_scores and test_scores each contain a 2-D array of values\n",
    "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
    "#   Take the mean for each depth across folds (columns, axis=1) \n",
    "#      and store in mean_train_scores and mean_test_scores\n",
    "mean_train_scores = np.mean(train_scores,axis=1)\n",
    "mean_test_scores = np.mean(test_scores,axis=1)\n",
    "\n",
    "# We should get 10 values between 0 and 1\n",
    "# Note that as depth increases, both train and test accuracy go up and then begin to diverge\n",
    "pd.DataFrame([mean_train_scores.round(2),mean_test_scores.round(2)],\n",
    "             columns=pd.Series(depths,name='max_depth'),\n",
    "             index=['mean_train_scores','mean_test_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 14. (4pts) Plot the validation curve\n",
    "\n",
    "# Plot mean_train_scores and mean_test_scores on the same plot\n",
    "#    create an axis to plot on using subplots, with figsize=(6,4)\n",
    "#    plot two lines using ax.plot()\n",
    "#      each with \"depths\" on the x-axis\n",
    "#      one for mean_train_scores on the y-axis with label \"train\"\n",
    "#      one for mean_test_scores on the y-axis with label \"test\"\n",
    "#    add a legend using ax.legend()\n",
    "#    label the x-axis as \"max_depth\" and the y-axis as \"mean accuracy\"\n",
    "# Note: use as many lines of code as necessary\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4))\n",
    "ax.plot(depths, mean_train_scores, 'o-', color='b',label='train');\n",
    "ax.plot(depths, mean_test_scores, 'o-', color='r', label='test');\n",
    "ax.set_xlabel('max_depth'), ax.set_ylabel('mean accuracy');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 GradientBoosting and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc best hyperparams      : {'max_depth': 3, 'n_estimators': 50}\n",
      "gbc best mean cv accuracy : 0.81\n"
     ]
    }
   ],
   "source": [
    "# 15. (4pts) Above we're looking at tuning a single hyperparameter (max_depth).\n",
    "#     Now let's tune two hyperparameters at the same time.\n",
    "#     Perform 3-fold cross validated grid search over number of trees and tree depth.\n",
    "\n",
    "# Import GridSearchCV from sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the grid of parameters to test\n",
    "#   The parameter settings to try are \n",
    "#   'n_estimators':[10,50,100,200],'max_depth':[1,2,3,5,10]\n",
    "params = {'n_estimators':[10,50,100,200],'max_depth':[1,2,3,5,10]}\n",
    "\n",
    "# Instantiate and fit GridSearchCV on the classification training set\n",
    "#   Use GradientBoostingClassifier with default arguments \n",
    "#   Use 3-folds\n",
    "#   Use default scoring (accuracy)\n",
    "#   Use refit=True (default) so the model is retrained on the entire training set\n",
    "#   Set n_jobs=-1 to use all cores\n",
    "gbc_gscv = GridSearchCV(GradientBoostingClassifier(),\n",
    "            param_grid=params,\n",
    "            cv=3,\n",
    "            scoring = \"accuracy\",\n",
    "            refit=True,\n",
    "            n_jobs = -1).fit(X_train_c,y_train_c) \n",
    "\n",
    "# Print out the best the best hyperparameter setting found (best_params_) \n",
    "#    and the mean accuracy they produced (best_score_)\n",
    "print(f'gbc best hyperparams      : {gbc_gscv.best_params_}')\n",
    "print(f'gbc best mean cv accuracy : {gbc_gscv.best_score_:.2f}')\n",
    "\n",
    "# Note that you may get different answers on different runs due to \n",
    "#   the random cv splits used at each grid point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.7 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model found: LogisticRegression\n",
      "logr test acc : 0.82\n",
      "gbc  test acc : 0.84\n"
     ]
    }
   ],
   "source": [
    "# 16. (4pts) Evaluate the best model on the test set\n",
    "\n",
    "# Which of our models has the highest training set cv accuracy?\n",
    "#   (GradientBoostingClassifier or LogisticRegression?)\n",
    "print('best model found: LogisticRegression')\n",
    "\n",
    "# To see how each of our models would generalize to new data,\n",
    "#     calculate the **test set** accuracy for each of our trained models\n",
    "\n",
    "# First, instantiate and train a new LogisticRegression model with default settings on the training set.\n",
    "# Note that, while we did train a LogisticRegression model several times when \n",
    "#  calculating the cross-validation accuracy, we never trained it on the full training set\n",
    "logr = LogisticRegression().fit(X_train_c, y_train_c)\n",
    "\n",
    "# Find the test set accuracy of both of our trained models\n",
    "# Recall that since we used refit=True when doing grid search\n",
    "#  on the GradientBoostingClassifier, we can use gbc_gscv.score() without retraining\n",
    "logr_test_acc = logr.score(X_test_c, y_test_c)\n",
    "gbc_test_acc = gbc_gscv.score(X_test_c, y_test_c)\n",
    "\n",
    "print(f'logr test acc : {logr_test_acc:.2f}')\n",
    "print(f'gbc  test acc : {gbc_test_acc:.2f}')\n",
    "\n",
    "# TO THINK ABOUT, BUT DON'T NEED TO ANSWER:\n",
    "# Did the model we chose have the best test set performance?\n",
    "# Is it guaranteed that the model with the best cv scores on the training set has the best test set score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
