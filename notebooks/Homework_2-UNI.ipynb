{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 2\n",
    "\n",
    "## [Name] - [UNI]\n",
    "\n",
    "### Due: Fri Mar 11th @ 11:59pm ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and hyperparameter tuning in both a regression and classification setting.\n",
    "\n",
    "We will be working with a small set of home sales data as we might see on a real-estate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Replace Name and UNI in the first cell and filename with your UNI and name.\n",
    "- Follow the comments below and fill in the blanks (____) to complete.\n",
    "- Where a text response is asked for, please enter as a comment, starting each line with #.\n",
    "\n",
    "\n",
    "Out of 50 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts) Set up our environment with common libraries and plot settings.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy as np, pandas as pd, matplotlib.pyplot as plt and seaborn as sns\n",
    "# Note: use as many lines of code as necessary\n",
    "____\n",
    "\n",
    "# Set the seaborn style to 'darkgrid'\n",
    "____\n",
    "\n",
    "# Execute the matplotlib magic function to ensure plots are displayed inline\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1 we will try to predict a real value home sale price using several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (4pts) Load and prepare our data.\n",
    "\n",
    "# Read in the csv file ../data/house_sales_subset.csv using pandas read_csv() with default parameter settings\n",
    "df = ____\n",
    "\n",
    "# Create a dataframe X which contains these 3 columns from df:\n",
    "#  'SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms'\n",
    "X = ____\n",
    "\n",
    "# Create a series y_r which contains only the column AdjSalePrice_x100000\n",
    "#    Note: the '_r' is for our regression target\n",
    "y_r = ____\n",
    "\n",
    "# Check that X and y_r is the correct shape\n",
    "assert X.shape == (1000,3)\n",
    "assert y_r.shape == (1000,)\n",
    "\n",
    "# To confirm that all features of X are similar in scale display the .describe() of X\n",
    "____\n",
    "\n",
    "# To get a sense of the distribution of the target, plot a histogram of y_r using sns.histplot()\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. (3pts) Create a held-aside set\n",
    "\n",
    "# Import train_test_split from sklearn\n",
    "____\n",
    "\n",
    "# Split X and y_r into 80% train and 20% test using train_test_split\n",
    "#   Use random_state=123 for grading consistency.\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = ____\n",
    "\n",
    "# Print out the the length of y_test_r divided by the length y_r  to confirm our test set size.\n",
    "print(f'proportion of data in test set: {____:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Baseline Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (3pts) Create a DummyRegressor and fit on the training set.\n",
    "\n",
    "# Import the DummyRegressor model from sklearn \n",
    "____\n",
    "\n",
    "# Instantiate a DummyRegessor model with strategy=\"mean\" \n",
    "dummy_r = ____\n",
    "\n",
    "# Train the DummyRegressor on the regression training set\n",
    "____\n",
    "\n",
    "# Calculate and print the training set R^2 score of the DummyRegressor\n",
    "dummy_r_training_r2 = ____\n",
    "\n",
    "print(f'dummy training set R^2: {dummy_r_training_r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Linear Regression and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (4pts) Train a Linear Regression model and calculate training set R^2.\n",
    "\n",
    "# Import the LinearRegression model from sklearn\n",
    "____\n",
    "\n",
    "# Instantiate a LinearRegression model with default arguments and fit on the training set\n",
    "lr = ____\n",
    "\n",
    "# Calculate and print the training set R^2 of the LinearRegression model\n",
    "lr_training_r2 = ____\n",
    "\n",
    "print(f'lr training set R^2: {lr_training_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (2pts) Use 5-fold Cross Validation to get a sense of variation \n",
    "#    of Liner Regression R^2 performance on the training set.\n",
    "\n",
    "# Import cross_val_score from sklearn.\n",
    "____\n",
    "\n",
    "# Generate 5-fold cross-validation R^2 scores \n",
    "#    for a LinearRegression model with default arguments \n",
    "#    on the training set\n",
    "lr_cv_scores = ____\n",
    "\n",
    "# Print out the R^2 scores found by cross_val_score\n",
    "np.round(lr_cv_scores,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (1pts) Calculate mean cv R^2 score +- 2 std. deviations\n",
    "\n",
    "# Calculate the mean cross validation score using the scores created above\n",
    "lr_cv_mean = ____\n",
    "\n",
    "# Calculate 2 standard deviations of the cross validation scores\n",
    "lr_cv_2std = ____\n",
    "\n",
    "# Print out the mean R^2 +- 2 standard variations for the LinearRegression model\n",
    "print(f'lr mean cv r2: {lr_cv_mean:.2f} +- {lr_cv_2std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. (2pts) Evaluate performance of our trained DummyRegressor and LinearRegression model on the test set.\n",
    "\n",
    "# Calculate R^2 on the test set using the previously trained models\n",
    "dummy_r_test_r2 = ____\n",
    "\n",
    "lr_test_r2 = ____\n",
    "\n",
    "print(f'dummy test R2 : {dummy_r_test_r2: .2f}')\n",
    "print(f'   lr test R2 : {lr_test_r2: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build several models to classify low vs. high adjusted sales price, creating a validation curve and performing grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reuse the same dataset, we'll first create a binary target for \n",
    "#    classification by thresholding at the mean of our AdjSalePrice\n",
    "\n",
    "# The classes are:\n",
    "#    Low AdjSalePrice  = 0\n",
    "#    High AdjSalePrice = 1\n",
    "\n",
    "y_c = (df.AdjSalePrice_x100000 > df.AdjSalePrice_x100000.mean()).astype(int)\n",
    "\n",
    "# Print out the unique labels and note it's 0,1 or binary classification\n",
    "y_c.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Create a Held-Aside Aet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (3pts) Create a training and test/held-aside set\n",
    "\n",
    "# Split into 80% train and 20% test using train_test_split \n",
    "#    Use the new y_c target and the same X we used for regression\n",
    "#    Stratify according to y_c so class proportions are the same in train and test\n",
    "#    Use random_state=123 for reproducibility\n",
    "#    Save the result into the variables X_train_c,X_test_c,y_train_c,y_test_c\n",
    "____\n",
    "\n",
    "# Print out the proportion of Low values (label of 0) in y_c\n",
    "print(f'proportion of low values: {____:0.2f}')\n",
    "\n",
    "# Assert that train and test have similar class proportions.\n",
    "# Find the proportion of Low (0) values in both y_train_c and y_test_c and \n",
    "#    assert that the absolute difference of these proportions is less than .01\n",
    "assert ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. (2pts)  Create a Dummy Classifier and confirm the expected performance on the training set.\n",
    "\n",
    "# Import DummyClassifier from sklearn\n",
    "____\n",
    "\n",
    "# Instantiate and a DummyClassifier with strategy=\"most_frequent\" and fit on the the training set\n",
    "dummy_c = ____\n",
    "\n",
    "# Print the trained DummyClassifier accuracy on the training set.\n",
    "# It should match the proportion of low values we saw above.\n",
    "print(f'dummy training set accuracy: {____:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3  Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. (3pts) It's good practice to start with a \"simple\" model.\n",
    "#     Train and calculate 5-fold cv training set accuracy for a Logistic Regression Classifier.\n",
    "\n",
    "# Import LogisticRegression from sklearn\n",
    "____\n",
    "\n",
    "# Generate 5-fold cross validation accuracy on the training set\n",
    "#    using LogisticRegression with default hyperparameters\n",
    "#    store as logr_cvscores\n",
    "logr_cv_scores = cross_val_score(LogisticRegression(),X_train_c,y_train_c)\n",
    "\n",
    "# Print out the mean cv accuracy for the LogisticRegression model\n",
    "print(f'logr mean cv accuracy: {____:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 GradientBoosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. (4pts) Now let's try a more complex model.\n",
    "#     Train and calculate 5-fold cv accuracy \n",
    "#     for a GradientBoosting model using the training set.\n",
    "\n",
    "# Import the GradientBoostingClassifier model from sklearn\n",
    "____\n",
    "\n",
    "# Calculate 5-fold cv training set accuracy scores for a GradientBoostingClassifier\n",
    "#   with 50 trees and max_depth=2\n",
    "#   To speed up training also set n_jobs=-1 in the cross_val_score (use one core for each fold)\n",
    "____\n",
    " \n",
    "# Calculate mean cv accuracy\n",
    "gbc_cv_mean = ____\n",
    "\n",
    "# Calculate 2 standard deviations for the cv scores\n",
    "gbc_cv_2std = ____\n",
    "\n",
    "print(f'gbc mean cv accuracy: {gbc_cv_mean:.2f} +- {gbc_cv_2std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 GradientBoosting and Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. (5pts) Let's investigate how the depth of trees (max_depth) affects performance.\n",
    "#     Generate a validation curve for tree depths in the GradientBoosting model.\n",
    "\n",
    "# Import the validation_curve function from sklearn\n",
    "____\n",
    "\n",
    "# In the GradientBoostingClassifier model, the depth of trees is set via max_depth\n",
    "# Here we'll try the depths 1,2,3,5,10\n",
    "depths = [1,2,3,5,10]\n",
    "\n",
    "# Generate the train_scores and test_scores for max_depth at different max_depths\n",
    "#   Use the validation_curve function\n",
    "#   Use a GradientBoostingClassiier with 50 trees\n",
    "#   Use our training set X_train_c, y_train_c\n",
    "#   Use the 'max_depth' parameter\n",
    "#   Use the depths list created above as the parameter range\n",
    "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
    "#   Use accuracy as the scoring metric\n",
    "#   Store the results in train_scores,test_scores\n",
    "train_scores,test_scores = ____\n",
    "\n",
    "# train_scores and test_scores each contain a 2-D array of values\n",
    "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
    "#   Take the mean for each depth across folds (columns, axis=1) \n",
    "#      and store in mean_train_scores and mean_test_scores\n",
    "mean_train_scores = ____\n",
    "mean_test_scores = ____\n",
    "\n",
    "# We should get 10 values between 0 and 1\n",
    "# Note that as depth increases, both train and test accuracy go up and then begin to diverge\n",
    "pd.DataFrame([mean_train_scores.round(2),mean_test_scores.round(2)],\n",
    "             columns=pd.Series(depths,name='max_depth'),\n",
    "             index=['mean_train_scores','mean_test_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. (4pts) Plot the validation curve\n",
    "\n",
    "# Plot mean_train_scores and mean_test_scores on the same plot\n",
    "#    create an axis to plot on using subplots, with figsize=(6,4)\n",
    "#    plot two lines using ax.plot()\n",
    "#      each with \"depths\" on the x-axis\n",
    "#      one for mean_train_scores on the y-axis with label \"train\"\n",
    "#      one for mean_test_scores on the y-axis with label \"test\"\n",
    "#    add a legend using ax.legend()\n",
    "#    label the x-axis as \"max_depth\" and the y-axis as \"mean accuracy\"\n",
    "# Note: use as many lines of code as necessary\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 GradientBoosting and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. (4pts) Above we're looking at tuning a single hyperparameter (max_depth).\n",
    "#     Now let's tune two hyperparameters at the same time.\n",
    "#     Perform 3-fold cross validated grid search over number of trees and tree depth.\n",
    "\n",
    "# Import GridSearchCV from sklearn\n",
    "____\n",
    "\n",
    "# Create the grid of parameters to test\n",
    "#   The parameter settings to try are \n",
    "#   'n_estimators':[10,50,100,200],'max_depth':[1,2,3,5,10]\n",
    "params = ____\n",
    "\n",
    "# Instantiate and fit GridSearchCV on the classification training set\n",
    "#   Use GradientBoostingClassifier with default arguments \n",
    "#   Use 3-folds\n",
    "#   Use default scoring (accuracy)\n",
    "#   Use refit=True (default) so the model is retrained on the entire training set\n",
    "#   Set n_jobs=-1 to use all cores\n",
    "gbc_gscv = ____\n",
    "\n",
    "# Print out the best the best hyperparameter setting found (best_params_) \n",
    "#    and the mean accuracy they produced (best_score_)\n",
    "print(f'gbc best hyperparams      : {____}')\n",
    "print(f'gbc best mean cv accuracy : {____:.2f}')\n",
    "\n",
    "# Note that you may get different answers on different runs due to \n",
    "#   the random cv splits used at each grid point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.7 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. (4pts) Evaluate the best model on the test set\n",
    "\n",
    "# Which of our models has the highest training set cv accuracy?\n",
    "#   (GradientBoostingClassifier or LogisticRegression?)\n",
    "print('best model found: ____')\n",
    "\n",
    "# To see how each of our models would generalize to new data,\n",
    "#     calculate the **test set** accuracy for each of our trained models\n",
    "\n",
    "# First, instantiate and train a new LogisticRegression model with default settings on the training set.\n",
    "# Note that, while we did train a LogisticRegression model several times when \n",
    "#  calculating the cross-validation accuracy, we never trained it on the full training set\n",
    "logr = ____\n",
    "\n",
    "# Find the test set accuracy of both of our trained models\n",
    "# Recall that since we used refit=True when doing grid search\n",
    "#  on the GradientBoostingClassifier, we can use gbc_gscv.score() without retraining\n",
    "logr_test_acc = ____\n",
    "gbc_test_acc = ____\n",
    "\n",
    "print(f'logr test acc : {logr_test_acc:.2f}')\n",
    "print(f'gbc  test acc : {gbc_test_acc:.2f}')\n",
    "\n",
    "# TO THINK ABOUT, BUT DON'T NEED TO ANSWER:\n",
    "# Did the model we chose have the best test set performance?\n",
    "# Is it guaranteed that the model with the best cv scores on the training set has the best test set score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
